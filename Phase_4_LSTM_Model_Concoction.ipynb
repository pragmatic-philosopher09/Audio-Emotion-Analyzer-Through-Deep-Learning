{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmatic-philosopher09/Audio-Emotion-Analyzer-Through-Deep-Learning/blob/main/Phase_4_LSTM_Model_Concoction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpcO__ZXQnWO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import keras\n",
        "#from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "zGA5lFAyD_HB",
        "outputId": "23c91849-1288-4171-f019-0e602589c4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0         0         1         2         3         4         5  \\\n",
              "0           0  0.272267  0.689451  0.708028  0.666473  0.715468  0.694820   \n",
              "1           1  0.262035  0.603476  0.668302  0.692199  0.709884  0.658301   \n",
              "2           2  0.195466  0.628032  0.687169  0.651985  0.621273  0.604192   \n",
              "3           3  0.173769  0.720864  0.685492  0.655122  0.652557  0.587786   \n",
              "4           4  0.207284  0.692981  0.737456  0.726056  0.685032  0.636497   \n",
              "\n",
              "          6         7         8  ...       152       153       154       155  \\\n",
              "0  0.627661  0.632560  0.687715  ...  0.000687  0.000502  0.000372  0.000197   \n",
              "1  0.605176  0.609343  0.640842  ...  0.000009  0.000012  0.000028  0.000034   \n",
              "2  0.640623  0.626136  0.652430  ...  0.000086  0.000107  0.000061  0.000052   \n",
              "3  0.550012  0.638170  0.707171  ...  0.000064  0.000051  0.000074  0.000129   \n",
              "4  0.568223  0.528898  0.598124  ...  0.000018  0.000014  0.000014  0.000005   \n",
              "\n",
              "        156       157       158       159           160  labels  \n",
              "0  0.000137  0.000288  0.000349  0.000143  1.498768e-05   angry  \n",
              "1  0.000036  0.000035  0.000032  0.000011  8.432723e-07    calm  \n",
              "2  0.000059  0.000095  0.000090  0.000031  2.326331e-06     sad  \n",
              "3  0.000198  0.000243  0.000190  0.000074  4.691918e-06    fear  \n",
              "4  0.000007  0.000011  0.000016  0.000008  4.218449e-07     sad  \n",
              "\n",
              "[5 rows x 163 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb8b4555-070e-408b-a4e5-1d6d56fb2e8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.272267</td>\n",
              "      <td>0.689451</td>\n",
              "      <td>0.708028</td>\n",
              "      <td>0.666473</td>\n",
              "      <td>0.715468</td>\n",
              "      <td>0.694820</td>\n",
              "      <td>0.627661</td>\n",
              "      <td>0.632560</td>\n",
              "      <td>0.687715</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000687</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>0.000372</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000137</td>\n",
              "      <td>0.000288</td>\n",
              "      <td>0.000349</td>\n",
              "      <td>0.000143</td>\n",
              "      <td>1.498768e-05</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.262035</td>\n",
              "      <td>0.603476</td>\n",
              "      <td>0.668302</td>\n",
              "      <td>0.692199</td>\n",
              "      <td>0.709884</td>\n",
              "      <td>0.658301</td>\n",
              "      <td>0.605176</td>\n",
              "      <td>0.609343</td>\n",
              "      <td>0.640842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>8.432723e-07</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.195466</td>\n",
              "      <td>0.628032</td>\n",
              "      <td>0.687169</td>\n",
              "      <td>0.651985</td>\n",
              "      <td>0.621273</td>\n",
              "      <td>0.604192</td>\n",
              "      <td>0.640623</td>\n",
              "      <td>0.626136</td>\n",
              "      <td>0.652430</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>2.326331e-06</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.173769</td>\n",
              "      <td>0.720864</td>\n",
              "      <td>0.685492</td>\n",
              "      <td>0.655122</td>\n",
              "      <td>0.652557</td>\n",
              "      <td>0.587786</td>\n",
              "      <td>0.550012</td>\n",
              "      <td>0.638170</td>\n",
              "      <td>0.707171</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000243</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>4.691918e-06</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.207284</td>\n",
              "      <td>0.692981</td>\n",
              "      <td>0.737456</td>\n",
              "      <td>0.726056</td>\n",
              "      <td>0.685032</td>\n",
              "      <td>0.636497</td>\n",
              "      <td>0.568223</td>\n",
              "      <td>0.528898</td>\n",
              "      <td>0.598124</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>4.218449e-07</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 163 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb8b4555-070e-408b-a4e5-1d6d56fb2e8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb8b4555-070e-408b-a4e5-1d6d56fb2e8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb8b4555-070e-408b-a4e5-1d6d56fb2e8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "Features = pd.read_csv('/content/drive/MyDrive/features_dataset.csv')\n",
        "Features.head()\n",
        "# Features.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhddYRu_FC9X",
        "outputId": "6d0b10bf-8c14-4484-f012-87a74d1d49db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "temp = shuffle(Features)\n",
        "# temp[:10]\n",
        "\n",
        "\n",
        "df = np.random.rand(len(temp)) < 0.8\n",
        "train = temp[df]\n",
        "test = temp[~df] # 1 - train basically\n",
        "\n",
        "\n",
        "trainfeatures = train.iloc[:, :-1]\n",
        "trainlabel = train.iloc[:, -1:]\n",
        "testfeatures = test.iloc[:, :-1]\n",
        "testlabel = test.iloc[:, -1:]\n",
        "\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_train = np.array(trainfeatures)\n",
        "y_train = np.array(trainlabel)\n",
        "X_test = np.array(testfeatures)\n",
        "y_test = np.array(testlabel)\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4D1KyKuFQxG"
      },
      "outputs": [],
      "source": [
        "# making our data compatible to model.\n",
        "x_train = np.expand_dims(X_train, axis=2)\n",
        "x_test = np.expand_dims(X_test, axis=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHqpOhVoFlza",
        "outputId": "a5f66139-bf5f-4f6a-937a-885191908364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dimension:\n",
            "(1141, 162, 1)\n",
            "Test dimension:\n",
            "(299, 162, 1)\n",
            "Train labels dimension:\n",
            "(1141, 8)\n",
            "Test labels dimension:\n",
            "(299, 8)\n"
          ]
        }
      ],
      "source": [
        "print('Train dimension:')\n",
        "print(x_train.shape)\n",
        "print('Test dimension:')\n",
        "print(x_test.shape)\n",
        "\n",
        "print('Train labels dimension:')\n",
        "print(y_train.shape)\n",
        "print('Test labels dimension:')\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JynYUMSFpp0"
      },
      "outputs": [],
      "source": [
        "# LSTM Classifier\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.regularizers import l2, l1, l1_l2\n",
        "\n",
        "from tensorflow.keras import layers,regularizers,models\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZnM7jtvFtS6",
        "outputId": "4e799413-6990-4b06-98a8-0457d1614f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_6 (Batc  (None, 162, 1)           4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 162, 256)          264192    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 162, 64)           82176     \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 162, 64)           33024     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 162, 64)          256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 10368)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 82952     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 462,604\n",
            "Trainable params: 462,474\n",
            "Non-trainable params: 130\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(axis=-1, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(LSTM(256, return_sequences=True,kernel_regularizer=regularizers.l2(1e-5)))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True,kernel_regularizer=regularizers.l2(1e-5)))\n",
        "\n",
        "model.add(LSTM(64, return_sequences=True,kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(32))\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(8))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(BatchNormalization(axis=-1, input_shape=(x_train.shape[1], 1)))\n",
        "# model.add(LSTM(256, return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(64, return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(32, return_sequences=True))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(32))\n",
        "# model.add(Activation('relu'))\n",
        "\n",
        "# model.add(Dense(8))\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# model = models.Sequential([\n",
        "#         layers.BatchNormalization(input_shape=(x_train.shape[1], 1)),\n",
        "#         layers.LSTM(256,dropout=0.2,recurrent_dropout=0.2,activation=None,return_sequences=True,kernel_regularizer=regularizers.l2(1e-5)),\n",
        "#         layers.LSTM(128,dropout=0.2,recurrent_dropout=0.2,return_sequences=True,kernel_regularizer=regularizers.l2(1e-5)),\n",
        "#         layers.LSTM(32,dropout=0.2,recurrent_dropout=0.2,return_sequences=True,activation=None,kernel_regularizer=regularizers.l2(1e-5)),\n",
        "#         layers.BatchNormalization(),\n",
        "\n",
        "#         layers.Flatten(),\n",
        "#         layers.Dense(256,activation='relu',kernel_regularizer=regularizers.l2(1e-5)),\n",
        "#         layers.Dropout(0.2),\n",
        "#         layers.BatchNormalization(),\n",
        "#         layers.Dense(8,activation='softmax'),\n",
        "# ])\n",
        "\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "# Configures the model for training\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'],callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gavz9wXJF1D-",
        "outputId": "4034a18c-71ae-4da9-ca87-c6a71681a0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.2924 - accuracy: 0.9316 - val_loss: 5.0368 - val_accuracy: 0.4649\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 3.3519 - accuracy: 0.5767 - val_loss: 7.5990 - val_accuracy: 0.3177\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 2.9799 - accuracy: 0.4733 - val_loss: 13.0597 - val_accuracy: 0.2709\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 1.9036 - accuracy: 0.4961 - val_loss: 11.0302 - val_accuracy: 0.2040\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 1.4035 - accuracy: 0.5600 - val_loss: 4.6679 - val_accuracy: 0.3645\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 1.1568 - accuracy: 0.6293 - val_loss: 4.6818 - val_accuracy: 0.3645\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 1.0222 - accuracy: 0.6459 - val_loss: 4.4703 - val_accuracy: 0.3679\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.8831 - accuracy: 0.6845 - val_loss: 3.5349 - val_accuracy: 0.4147\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.8053 - accuracy: 0.7283 - val_loss: 2.8170 - val_accuracy: 0.4381\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.7023 - accuracy: 0.7476 - val_loss: 2.2490 - val_accuracy: 0.4950\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.6028 - accuracy: 0.7818 - val_loss: 2.4122 - val_accuracy: 0.5050\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.5167 - accuracy: 0.8230 - val_loss: 1.7640 - val_accuracy: 0.5753\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.5364 - accuracy: 0.8160 - val_loss: 2.4653 - val_accuracy: 0.5351\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.4627 - accuracy: 0.8387 - val_loss: 1.8905 - val_accuracy: 0.5819\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.5110 - accuracy: 0.8387 - val_loss: 2.3555 - val_accuracy: 0.5452\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.4704 - accuracy: 0.8475 - val_loss: 2.8516 - val_accuracy: 0.5117\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.5246 - accuracy: 0.8344 - val_loss: 2.5414 - val_accuracy: 0.5151\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.4512 - accuracy: 0.8352 - val_loss: 2.3502 - val_accuracy: 0.5619\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.3030 - accuracy: 0.8887 - val_loss: 2.1907 - val_accuracy: 0.5886\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.2897 - accuracy: 0.8975 - val_loss: 2.8012 - val_accuracy: 0.5418\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.2893 - accuracy: 0.8983 - val_loss: 2.1934 - val_accuracy: 0.5786\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.2668 - accuracy: 0.9089 - val_loss: 2.5069 - val_accuracy: 0.5686\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.2185 - accuracy: 0.9290 - val_loss: 2.6463 - val_accuracy: 0.5452\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.2851 - accuracy: 0.9089 - val_loss: 2.5580 - val_accuracy: 0.5518\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.2411 - accuracy: 0.9202 - val_loss: 2.3883 - val_accuracy: 0.5619\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1716 - accuracy: 0.9422 - val_loss: 2.3105 - val_accuracy: 0.5886\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1773 - accuracy: 0.9351 - val_loss: 2.7883 - val_accuracy: 0.5585\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3366 - accuracy: 0.8869 - val_loss: 2.4113 - val_accuracy: 0.5786\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2246 - accuracy: 0.9246 - val_loss: 2.5926 - val_accuracy: 0.5552\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1341 - accuracy: 0.9544 - val_loss: 2.7047 - val_accuracy: 0.5853\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1872 - accuracy: 0.9369 - val_loss: 2.4834 - val_accuracy: 0.5987\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1825 - accuracy: 0.9395 - val_loss: 2.3767 - val_accuracy: 0.5753\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1074 - accuracy: 0.9658 - val_loss: 2.7253 - val_accuracy: 0.5819\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1004 - accuracy: 0.9684 - val_loss: 2.4279 - val_accuracy: 0.5753\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0947 - accuracy: 0.9711 - val_loss: 2.4076 - val_accuracy: 0.5886\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1059 - accuracy: 0.9667 - val_loss: 2.4524 - val_accuracy: 0.5953\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0823 - accuracy: 0.9693 - val_loss: 2.5352 - val_accuracy: 0.5819\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0989 - accuracy: 0.9702 - val_loss: 2.6682 - val_accuracy: 0.5853\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1139 - accuracy: 0.9684 - val_loss: 2.4806 - val_accuracy: 0.6054\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0793 - accuracy: 0.9781 - val_loss: 2.4309 - val_accuracy: 0.6087\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0731 - accuracy: 0.9816 - val_loss: 2.5056 - val_accuracy: 0.6087\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0931 - accuracy: 0.9711 - val_loss: 2.8670 - val_accuracy: 0.5886\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0994 - accuracy: 0.9649 - val_loss: 2.6716 - val_accuracy: 0.5853\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0887 - accuracy: 0.9711 - val_loss: 2.6464 - val_accuracy: 0.5686\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0817 - accuracy: 0.9781 - val_loss: 2.5402 - val_accuracy: 0.5853\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0822 - accuracy: 0.9798 - val_loss: 2.6041 - val_accuracy: 0.5953\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0882 - accuracy: 0.9728 - val_loss: 2.7163 - val_accuracy: 0.5886\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0807 - accuracy: 0.9763 - val_loss: 2.5760 - val_accuracy: 0.6020\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0798 - accuracy: 0.9816 - val_loss: 2.6957 - val_accuracy: 0.5753\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0722 - accuracy: 0.9833 - val_loss: 2.7582 - val_accuracy: 0.5719\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.1073 - accuracy: 0.9720 - val_loss: 2.9396 - val_accuracy: 0.5585\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2001 - accuracy: 0.9395 - val_loss: 2.5736 - val_accuracy: 0.5619\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2679 - accuracy: 0.9273 - val_loss: 2.4193 - val_accuracy: 0.5886\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2641 - accuracy: 0.9229 - val_loss: 3.2717 - val_accuracy: 0.5251\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2093 - accuracy: 0.9334 - val_loss: 2.4480 - val_accuracy: 0.5552\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2182 - accuracy: 0.9281 - val_loss: 2.6220 - val_accuracy: 0.5585\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1791 - accuracy: 0.9351 - val_loss: 2.4963 - val_accuracy: 0.5920\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1116 - accuracy: 0.9649 - val_loss: 2.5327 - val_accuracy: 0.6020\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0938 - accuracy: 0.9720 - val_loss: 2.8546 - val_accuracy: 0.6120\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0864 - accuracy: 0.9693 - val_loss: 2.8066 - val_accuracy: 0.6187\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1263 - accuracy: 0.9588 - val_loss: 2.6822 - val_accuracy: 0.5987\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1313 - accuracy: 0.9588 - val_loss: 2.6261 - val_accuracy: 0.6120\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1250 - accuracy: 0.9588 - val_loss: 2.9019 - val_accuracy: 0.5953\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0852 - accuracy: 0.9781 - val_loss: 3.0219 - val_accuracy: 0.5819\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1331 - accuracy: 0.9623 - val_loss: 2.8560 - val_accuracy: 0.5552\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2386 - accuracy: 0.9360 - val_loss: 3.0580 - val_accuracy: 0.5318\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3105 - accuracy: 0.9089 - val_loss: 2.8146 - val_accuracy: 0.5585\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1822 - accuracy: 0.9404 - val_loss: 2.8827 - val_accuracy: 0.5518\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1270 - accuracy: 0.9641 - val_loss: 2.6112 - val_accuracy: 0.5753\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1256 - accuracy: 0.9579 - val_loss: 2.7660 - val_accuracy: 0.5953\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0807 - accuracy: 0.9755 - val_loss: 2.4959 - val_accuracy: 0.6020\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0998 - accuracy: 0.9702 - val_loss: 3.0152 - val_accuracy: 0.5987\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0781 - accuracy: 0.9772 - val_loss: 2.5997 - val_accuracy: 0.6120\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0424 - accuracy: 0.9912 - val_loss: 2.4774 - val_accuracy: 0.6087\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0461 - accuracy: 0.9886 - val_loss: 2.8548 - val_accuracy: 0.5853\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0507 - accuracy: 0.9886 - val_loss: 2.5190 - val_accuracy: 0.5786\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0783 - accuracy: 0.9816 - val_loss: 2.5939 - val_accuracy: 0.5920\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0733 - accuracy: 0.9833 - val_loss: 2.7722 - val_accuracy: 0.5552\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1329 - accuracy: 0.9632 - val_loss: 2.7413 - val_accuracy: 0.6120\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1707 - accuracy: 0.9535 - val_loss: 2.6424 - val_accuracy: 0.6120\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1410 - accuracy: 0.9588 - val_loss: 2.7632 - val_accuracy: 0.5619\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1557 - accuracy: 0.9518 - val_loss: 3.1648 - val_accuracy: 0.5819\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1866 - accuracy: 0.9343 - val_loss: 2.9613 - val_accuracy: 0.5418\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1262 - accuracy: 0.9676 - val_loss: 2.7016 - val_accuracy: 0.5886\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1635 - accuracy: 0.9448 - val_loss: 3.0974 - val_accuracy: 0.5418\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1907 - accuracy: 0.9413 - val_loss: 2.6652 - val_accuracy: 0.6054\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1437 - accuracy: 0.9483 - val_loss: 2.7490 - val_accuracy: 0.5819\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1411 - accuracy: 0.9492 - val_loss: 2.7470 - val_accuracy: 0.6120\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0872 - accuracy: 0.9711 - val_loss: 2.8738 - val_accuracy: 0.5518\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 2.4560 - val_accuracy: 0.6120\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0589 - accuracy: 0.9842 - val_loss: 2.5775 - val_accuracy: 0.6087\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0420 - accuracy: 0.9921 - val_loss: 2.6532 - val_accuracy: 0.6154\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0239 - accuracy: 0.9991 - val_loss: 2.7108 - val_accuracy: 0.6054\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0279 - accuracy: 0.9965 - val_loss: 2.6266 - val_accuracy: 0.6087\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0231 - accuracy: 0.9982 - val_loss: 2.8141 - val_accuracy: 0.6187\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0237 - accuracy: 0.9947 - val_loss: 2.6708 - val_accuracy: 0.5987\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0270 - accuracy: 0.9947 - val_loss: 2.7919 - val_accuracy: 0.5920\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0486 - accuracy: 0.9886 - val_loss: 2.9490 - val_accuracy: 0.6288\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0601 - accuracy: 0.9781 - val_loss: 2.8631 - val_accuracy: 0.5953\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0816 - accuracy: 0.9816 - val_loss: 2.7439 - val_accuracy: 0.6020\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1072 - accuracy: 0.9711 - val_loss: 3.1378 - val_accuracy: 0.5987\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1281 - accuracy: 0.9579 - val_loss: 2.3129 - val_accuracy: 0.6187\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0814 - accuracy: 0.9781 - val_loss: 2.6196 - val_accuracy: 0.5886\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0472 - accuracy: 0.9886 - val_loss: 2.6169 - val_accuracy: 0.6355\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0434 - accuracy: 0.9895 - val_loss: 2.6190 - val_accuracy: 0.5987\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 2.5618 - val_accuracy: 0.5920\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0353 - accuracy: 0.9939 - val_loss: 2.5005 - val_accuracy: 0.5987\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0460 - accuracy: 0.9877 - val_loss: 2.7331 - val_accuracy: 0.6120\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1026 - accuracy: 0.9702 - val_loss: 2.8117 - val_accuracy: 0.5719\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1497 - accuracy: 0.9597 - val_loss: 2.6742 - val_accuracy: 0.6187\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1475 - accuracy: 0.9535 - val_loss: 2.6496 - val_accuracy: 0.5652\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1306 - accuracy: 0.9509 - val_loss: 2.5661 - val_accuracy: 0.6087\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0903 - accuracy: 0.9711 - val_loss: 3.2421 - val_accuracy: 0.5819\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0964 - accuracy: 0.9693 - val_loss: 3.1057 - val_accuracy: 0.5987\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1070 - accuracy: 0.9658 - val_loss: 2.8591 - val_accuracy: 0.5819\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1368 - accuracy: 0.9606 - val_loss: 2.7344 - val_accuracy: 0.5719\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0611 - accuracy: 0.9851 - val_loss: 2.9263 - val_accuracy: 0.5853\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0531 - accuracy: 0.9886 - val_loss: 2.7086 - val_accuracy: 0.5886\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0423 - accuracy: 0.9904 - val_loss: 2.9074 - val_accuracy: 0.6087\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0627 - accuracy: 0.9798 - val_loss: 2.8024 - val_accuracy: 0.5819\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0466 - accuracy: 0.9895 - val_loss: 2.7017 - val_accuracy: 0.6254\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0715 - accuracy: 0.9833 - val_loss: 3.1561 - val_accuracy: 0.5786\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1262 - accuracy: 0.9632 - val_loss: 3.4116 - val_accuracy: 0.5753\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.1183 - accuracy: 0.9658 - val_loss: 2.8454 - val_accuracy: 0.5886\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0688 - accuracy: 0.9825 - val_loss: 2.9026 - val_accuracy: 0.6120\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0619 - accuracy: 0.9833 - val_loss: 2.8956 - val_accuracy: 0.6020\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0706 - accuracy: 0.9772 - val_loss: 2.9188 - val_accuracy: 0.6254\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0616 - accuracy: 0.9842 - val_loss: 3.0002 - val_accuracy: 0.5819\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0999 - accuracy: 0.9720 - val_loss: 3.1024 - val_accuracy: 0.6054\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0890 - accuracy: 0.9746 - val_loss: 2.9039 - val_accuracy: 0.6020\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1284 - accuracy: 0.9535 - val_loss: 2.7117 - val_accuracy: 0.6120\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2014 - accuracy: 0.9465 - val_loss: 3.3158 - val_accuracy: 0.5853\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1489 - accuracy: 0.9553 - val_loss: 2.8746 - val_accuracy: 0.6087\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1396 - accuracy: 0.9571 - val_loss: 3.5200 - val_accuracy: 0.5385\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.1419 - accuracy: 0.9623 - val_loss: 3.3563 - val_accuracy: 0.5819\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0952 - accuracy: 0.9763 - val_loss: 3.0860 - val_accuracy: 0.5719\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0932 - accuracy: 0.9728 - val_loss: 3.1241 - val_accuracy: 0.5953\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0782 - accuracy: 0.9781 - val_loss: 2.6191 - val_accuracy: 0.5920\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0869 - accuracy: 0.9737 - val_loss: 2.7952 - val_accuracy: 0.6120\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 2.9184 - val_accuracy: 0.5819\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0654 - accuracy: 0.9842 - val_loss: 2.8655 - val_accuracy: 0.6087\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0848 - accuracy: 0.9737 - val_loss: 3.2265 - val_accuracy: 0.5351\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1652 - accuracy: 0.9571 - val_loss: 2.8613 - val_accuracy: 0.5786\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.1931 - accuracy: 0.9430 - val_loss: 3.2174 - val_accuracy: 0.5819\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.1960 - accuracy: 0.9492 - val_loss: 2.6456 - val_accuracy: 0.6054\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0913 - accuracy: 0.9737 - val_loss: 2.8202 - val_accuracy: 0.5819\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0613 - accuracy: 0.9860 - val_loss: 2.9193 - val_accuracy: 0.6020\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 2.8545 - val_accuracy: 0.6154\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 2.8438 - val_accuracy: 0.5886\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 3.0126 - val_accuracy: 0.6020\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0464 - accuracy: 0.9877 - val_loss: 3.0939 - val_accuracy: 0.5920\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0368 - accuracy: 0.9930 - val_loss: 2.8169 - val_accuracy: 0.6187\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0270 - accuracy: 0.9965 - val_loss: 2.8399 - val_accuracy: 0.6120\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0284 - accuracy: 0.9947 - val_loss: 2.7180 - val_accuracy: 0.6187\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0284 - accuracy: 0.9947 - val_loss: 2.6625 - val_accuracy: 0.6020\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0255 - accuracy: 0.9956 - val_loss: 2.7521 - val_accuracy: 0.6054\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0476 - accuracy: 0.9886 - val_loss: 2.8646 - val_accuracy: 0.6221\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0211 - accuracy: 0.9982 - val_loss: 2.6188 - val_accuracy: 0.6288\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0345 - accuracy: 0.9921 - val_loss: 3.1364 - val_accuracy: 0.5786\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0239 - accuracy: 0.9965 - val_loss: 2.6436 - val_accuracy: 0.6187\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0194 - accuracy: 0.9965 - val_loss: 2.8266 - val_accuracy: 0.5987\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0328 - accuracy: 0.9921 - val_loss: 2.7316 - val_accuracy: 0.6221\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0257 - accuracy: 0.9974 - val_loss: 2.9311 - val_accuracy: 0.6087\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0282 - accuracy: 0.9939 - val_loss: 2.6984 - val_accuracy: 0.6087\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 2.9780 - val_accuracy: 0.6187\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0323 - accuracy: 0.9947 - val_loss: 2.8249 - val_accuracy: 0.6087\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 2.9707 - val_accuracy: 0.6154\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 2.7999 - val_accuracy: 0.6154\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0202 - accuracy: 0.9982 - val_loss: 2.9071 - val_accuracy: 0.6221\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.0184 - accuracy: 0.9982 - val_loss: 2.8512 - val_accuracy: 0.6288\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.0152 - accuracy: 0.9982 - val_loss: 2.8876 - val_accuracy: 0.6120\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 2.9301 - val_accuracy: 0.6221\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 2.9957 - val_accuracy: 0.6187\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0323 - accuracy: 0.9912 - val_loss: 3.2566 - val_accuracy: 0.5920\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0812 - accuracy: 0.9825 - val_loss: 3.3087 - val_accuracy: 0.5786\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0806 - accuracy: 0.9763 - val_loss: 3.2658 - val_accuracy: 0.5920\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2175 - accuracy: 0.9509 - val_loss: 3.4200 - val_accuracy: 0.5920\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.4073 - accuracy: 0.9001 - val_loss: 3.3430 - val_accuracy: 0.5619\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.3229 - accuracy: 0.9115 - val_loss: 4.6586 - val_accuracy: 0.4783\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.7146 - accuracy: 0.8431 - val_loss: 3.5863 - val_accuracy: 0.5452\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.5951 - accuracy: 0.8457 - val_loss: 3.7100 - val_accuracy: 0.5284\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.3097 - accuracy: 0.9115 - val_loss: 3.2512 - val_accuracy: 0.5853\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2105 - accuracy: 0.9264 - val_loss: 3.1019 - val_accuracy: 0.5351\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1563 - accuracy: 0.9518 - val_loss: 2.9516 - val_accuracy: 0.6120\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1100 - accuracy: 0.9684 - val_loss: 3.0530 - val_accuracy: 0.5819\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0922 - accuracy: 0.9737 - val_loss: 2.9508 - val_accuracy: 0.5953\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0875 - accuracy: 0.9702 - val_loss: 3.0777 - val_accuracy: 0.5920\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0942 - accuracy: 0.9702 - val_loss: 2.9447 - val_accuracy: 0.6087\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0472 - accuracy: 0.9816 - val_loss: 3.0413 - val_accuracy: 0.6054\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0680 - accuracy: 0.9842 - val_loss: 2.7318 - val_accuracy: 0.6054\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0448 - accuracy: 0.9921 - val_loss: 2.8605 - val_accuracy: 0.5886\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0495 - accuracy: 0.9869 - val_loss: 2.8432 - val_accuracy: 0.6120\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0312 - accuracy: 0.9947 - val_loss: 2.8711 - val_accuracy: 0.6087\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0306 - accuracy: 0.9956 - val_loss: 2.9802 - val_accuracy: 0.6087\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0405 - accuracy: 0.9895 - val_loss: 2.9253 - val_accuracy: 0.5886\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0416 - accuracy: 0.9895 - val_loss: 3.0295 - val_accuracy: 0.5886\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0701 - accuracy: 0.9860 - val_loss: 2.8635 - val_accuracy: 0.5819\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1009 - accuracy: 0.9746 - val_loss: 3.0140 - val_accuracy: 0.5686\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1173 - accuracy: 0.9755 - val_loss: 2.7538 - val_accuracy: 0.6120\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0759 - accuracy: 0.9790 - val_loss: 3.0400 - val_accuracy: 0.5819\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1131 - accuracy: 0.9658 - val_loss: 3.1454 - val_accuracy: 0.5853\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 2.4682 - val_accuracy: 0.6154\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0464 - accuracy: 0.9869 - val_loss: 2.9006 - val_accuracy: 0.5920\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0294 - accuracy: 0.9939 - val_loss: 2.8131 - val_accuracy: 0.5518\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 2.7728 - val_accuracy: 0.5953\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0190 - accuracy: 0.9974 - val_loss: 2.6987 - val_accuracy: 0.5987\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.7054 - val_accuracy: 0.6221\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.7060 - val_accuracy: 0.6187\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.6866 - val_accuracy: 0.6154\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.6860 - val_accuracy: 0.6087\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.6696 - val_accuracy: 0.6154\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0215 - accuracy: 0.9965 - val_loss: 2.9022 - val_accuracy: 0.5886\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0192 - accuracy: 0.9974 - val_loss: 2.8066 - val_accuracy: 0.5987\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.8546 - val_accuracy: 0.6020\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.7471 - val_accuracy: 0.5953\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.7342 - val_accuracy: 0.5920\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.7284 - val_accuracy: 0.5953\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.6929 - val_accuracy: 0.5920\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0354 - accuracy: 0.9921 - val_loss: 2.8733 - val_accuracy: 0.5719\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.3635 - accuracy: 0.9185 - val_loss: 3.2107 - val_accuracy: 0.5518\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3936 - accuracy: 0.9018 - val_loss: 3.4195 - val_accuracy: 0.5552\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3117 - accuracy: 0.9115 - val_loss: 3.0982 - val_accuracy: 0.5953\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1537 - accuracy: 0.9562 - val_loss: 3.1365 - val_accuracy: 0.5619\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 0.0811 - accuracy: 0.9798 - val_loss: 2.8981 - val_accuracy: 0.6120\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.0530 - accuracy: 0.9869 - val_loss: 3.2221 - val_accuracy: 0.6020\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0457 - accuracy: 0.9877 - val_loss: 2.8319 - val_accuracy: 0.6120\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0489 - accuracy: 0.9895 - val_loss: 2.7744 - val_accuracy: 0.6054\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 2.6825 - val_accuracy: 0.6187\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0227 - accuracy: 0.9974 - val_loss: 2.8689 - val_accuracy: 0.6355\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 2.6922 - val_accuracy: 0.6120\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0213 - accuracy: 0.9974 - val_loss: 2.7688 - val_accuracy: 0.6254\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0191 - accuracy: 0.9982 - val_loss: 2.7180 - val_accuracy: 0.6154\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.7146 - val_accuracy: 0.6154\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.7644 - val_accuracy: 0.6288\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.7275 - val_accuracy: 0.6221\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.7672 - val_accuracy: 0.6221\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.7672 - val_accuracy: 0.6388\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.7716 - val_accuracy: 0.6355\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.7680 - val_accuracy: 0.6355\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.7649 - val_accuracy: 0.6254\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.7786 - val_accuracy: 0.6355\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0143 - accuracy: 0.9991 - val_loss: 2.7755 - val_accuracy: 0.6154\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 2.8156 - val_accuracy: 0.6187\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0144 - accuracy: 0.9991 - val_loss: 2.7342 - val_accuracy: 0.6120\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.6187\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.7687 - val_accuracy: 0.6120\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.6154\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.8060 - val_accuracy: 0.6254\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.6288\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.6321\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.8043 - val_accuracy: 0.6254\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.8124 - val_accuracy: 0.6254\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.8141 - val_accuracy: 0.6288\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.7989 - val_accuracy: 0.6254\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.8194 - val_accuracy: 0.6288\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.8177 - val_accuracy: 0.6288\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.8305 - val_accuracy: 0.6288\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.8832 - val_accuracy: 0.6321\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.8912 - val_accuracy: 0.6221\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.8518 - val_accuracy: 0.6254\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.8546 - val_accuracy: 0.6254\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.8591 - val_accuracy: 0.6355\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.8635 - val_accuracy: 0.6187\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.8670 - val_accuracy: 0.6288\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.9244 - val_accuracy: 0.6154\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.9991 - val_loss: 2.9116 - val_accuracy: 0.6221\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0235 - accuracy: 0.9947 - val_loss: 2.8880 - val_accuracy: 0.5987\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0213 - accuracy: 0.9956 - val_loss: 2.9008 - val_accuracy: 0.6087\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0340 - accuracy: 0.9939 - val_loss: 2.9120 - val_accuracy: 0.5819\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0370 - accuracy: 0.9904 - val_loss: 3.2147 - val_accuracy: 0.5652\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0390 - accuracy: 0.9921 - val_loss: 3.2107 - val_accuracy: 0.5786\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0795 - accuracy: 0.9825 - val_loss: 2.8892 - val_accuracy: 0.5786\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0988 - accuracy: 0.9702 - val_loss: 3.1821 - val_accuracy: 0.5920\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0952 - accuracy: 0.9728 - val_loss: 3.0257 - val_accuracy: 0.6187\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1408 - accuracy: 0.9597 - val_loss: 3.0570 - val_accuracy: 0.5953\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.3797 - accuracy: 0.9027 - val_loss: 3.8840 - val_accuracy: 0.5017\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.4004 - accuracy: 0.8834 - val_loss: 3.4836 - val_accuracy: 0.5552\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.3130 - accuracy: 0.9089 - val_loss: 3.6503 - val_accuracy: 0.5452\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2302 - accuracy: 0.9264 - val_loss: 3.3417 - val_accuracy: 0.5518\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2163 - accuracy: 0.9474 - val_loss: 3.1398 - val_accuracy: 0.5719\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.2209 - accuracy: 0.9430 - val_loss: 3.3201 - val_accuracy: 0.5585\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1584 - accuracy: 0.9527 - val_loss: 3.3447 - val_accuracy: 0.5719\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0799 - accuracy: 0.9772 - val_loss: 3.3355 - val_accuracy: 0.5753\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1084 - accuracy: 0.9684 - val_loss: 2.8936 - val_accuracy: 0.5886\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1246 - accuracy: 0.9676 - val_loss: 3.6814 - val_accuracy: 0.5686\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1222 - accuracy: 0.9728 - val_loss: 2.9160 - val_accuracy: 0.6288\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1020 - accuracy: 0.9728 - val_loss: 2.9955 - val_accuracy: 0.5753\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0790 - accuracy: 0.9781 - val_loss: 2.7852 - val_accuracy: 0.5786\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0652 - accuracy: 0.9825 - val_loss: 2.9535 - val_accuracy: 0.5753\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0513 - accuracy: 0.9904 - val_loss: 2.9956 - val_accuracy: 0.5719\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0307 - accuracy: 0.9939 - val_loss: 2.9805 - val_accuracy: 0.5987\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 3.0909 - val_accuracy: 0.5753\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0215 - accuracy: 0.9982 - val_loss: 2.9441 - val_accuracy: 0.5686\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0337 - accuracy: 0.9930 - val_loss: 2.9719 - val_accuracy: 0.5987\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0368 - accuracy: 0.9939 - val_loss: 3.4541 - val_accuracy: 0.5886\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 3.3655 - val_accuracy: 0.5987\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 3.1811 - val_accuracy: 0.5853\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 3.2559 - val_accuracy: 0.5753\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0168 - accuracy: 0.9991 - val_loss: 3.3225 - val_accuracy: 0.5886\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0228 - accuracy: 0.9974 - val_loss: 3.2098 - val_accuracy: 0.5920\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0230 - accuracy: 0.9965 - val_loss: 3.1195 - val_accuracy: 0.5920\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0178 - accuracy: 0.9982 - val_loss: 3.0553 - val_accuracy: 0.6054\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0165 - accuracy: 0.9991 - val_loss: 2.9593 - val_accuracy: 0.6221\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9991 - val_loss: 2.9361 - val_accuracy: 0.6087\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0125 - accuracy: 0.9991 - val_loss: 2.9269 - val_accuracy: 0.6120\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0125 - accuracy: 0.9991 - val_loss: 2.9154 - val_accuracy: 0.6187\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 2.9600 - val_accuracy: 0.6087\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 3.0135 - val_accuracy: 0.5853\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.9810 - val_accuracy: 0.5920\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.9745 - val_accuracy: 0.5987\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.9637 - val_accuracy: 0.5953\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0164 - accuracy: 0.9982 - val_loss: 2.9782 - val_accuracy: 0.6054\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 2.9953 - val_accuracy: 0.6020\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 3.1286 - val_accuracy: 0.6087\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0140 - accuracy: 0.9991 - val_loss: 2.9489 - val_accuracy: 0.6154\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0147 - accuracy: 0.9991 - val_loss: 3.0805 - val_accuracy: 0.5953\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0133 - accuracy: 0.9991 - val_loss: 3.0449 - val_accuracy: 0.6087\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 3.0107 - val_accuracy: 0.6154\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.9579 - val_accuracy: 0.6154\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 3.0643 - val_accuracy: 0.5853\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0487 - accuracy: 0.9869 - val_loss: 3.8377 - val_accuracy: 0.5786\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0669 - accuracy: 0.9842 - val_loss: 3.2189 - val_accuracy: 0.5953\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1005 - accuracy: 0.9693 - val_loss: 3.1165 - val_accuracy: 0.5886\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1380 - accuracy: 0.9606 - val_loss: 3.5177 - val_accuracy: 0.5786\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1295 - accuracy: 0.9632 - val_loss: 3.7350 - val_accuracy: 0.5753\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1584 - accuracy: 0.9535 - val_loss: 3.1359 - val_accuracy: 0.6054\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1460 - accuracy: 0.9597 - val_loss: 3.7287 - val_accuracy: 0.5585\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1516 - accuracy: 0.9588 - val_loss: 3.1504 - val_accuracy: 0.5953\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.1631 - accuracy: 0.9518 - val_loss: 2.9051 - val_accuracy: 0.5585\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0940 - accuracy: 0.9763 - val_loss: 2.9134 - val_accuracy: 0.6187\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1116 - accuracy: 0.9623 - val_loss: 2.9635 - val_accuracy: 0.5953\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1347 - accuracy: 0.9623 - val_loss: 3.8265 - val_accuracy: 0.6020\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1412 - accuracy: 0.9544 - val_loss: 3.2472 - val_accuracy: 0.5953\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1532 - accuracy: 0.9518 - val_loss: 3.1109 - val_accuracy: 0.5853\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1121 - accuracy: 0.9623 - val_loss: 3.1668 - val_accuracy: 0.6288\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0796 - accuracy: 0.9798 - val_loss: 3.0979 - val_accuracy: 0.5953\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0513 - accuracy: 0.9851 - val_loss: 3.5804 - val_accuracy: 0.5886\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0408 - accuracy: 0.9895 - val_loss: 3.1802 - val_accuracy: 0.6054\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0410 - accuracy: 0.9921 - val_loss: 3.4383 - val_accuracy: 0.5920\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0402 - accuracy: 0.9904 - val_loss: 3.3150 - val_accuracy: 0.5987\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0303 - accuracy: 0.9947 - val_loss: 3.3231 - val_accuracy: 0.5953\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0225 - accuracy: 0.9956 - val_loss: 3.3199 - val_accuracy: 0.5853\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 3.1523 - val_accuracy: 0.5886\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 3.2070 - val_accuracy: 0.6020\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0185 - accuracy: 0.9974 - val_loss: 3.0958 - val_accuracy: 0.6120\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0173 - accuracy: 0.9991 - val_loss: 3.1218 - val_accuracy: 0.5987\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0180 - accuracy: 0.9965 - val_loss: 3.0039 - val_accuracy: 0.6254\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0185 - accuracy: 0.9982 - val_loss: 3.2598 - val_accuracy: 0.5786\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 2.9801 - val_accuracy: 0.6120\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0154 - accuracy: 0.9991 - val_loss: 3.1951 - val_accuracy: 0.5920\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0157 - accuracy: 0.9991 - val_loss: 3.0394 - val_accuracy: 0.5987\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0156 - accuracy: 0.9991 - val_loss: 3.0780 - val_accuracy: 0.5819\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0135 - accuracy: 0.9991 - val_loss: 3.1476 - val_accuracy: 0.5987\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 0.9991 - val_loss: 3.0492 - val_accuracy: 0.5853\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0171 - accuracy: 0.9982 - val_loss: 3.2470 - val_accuracy: 0.5920\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0163 - accuracy: 0.9974 - val_loss: 3.1510 - val_accuracy: 0.6120\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.0150 - accuracy: 0.9991 - val_loss: 3.1524 - val_accuracy: 0.6154\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 3.1805 - val_accuracy: 0.5987\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9991 - val_loss: 3.1387 - val_accuracy: 0.6154\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0162 - accuracy: 0.9982 - val_loss: 3.1527 - val_accuracy: 0.5987\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9982 - val_loss: 3.1695 - val_accuracy: 0.5953\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 3.0855 - val_accuracy: 0.6221\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0141 - accuracy: 0.9991 - val_loss: 3.1752 - val_accuracy: 0.6087\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0206 - accuracy: 0.9974 - val_loss: 3.0702 - val_accuracy: 0.6087\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0190 - accuracy: 0.9974 - val_loss: 3.0883 - val_accuracy: 0.6288\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0176 - accuracy: 0.9974 - val_loss: 3.3304 - val_accuracy: 0.6054\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 3.2220 - val_accuracy: 0.6020\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 3.0995 - val_accuracy: 0.6087\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.1196 - val_accuracy: 0.6087\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 3.1437 - val_accuracy: 0.6087\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0156 - accuracy: 0.9991 - val_loss: 3.1561 - val_accuracy: 0.5987\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0166 - accuracy: 0.9982 - val_loss: 3.2802 - val_accuracy: 0.6221\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0304 - accuracy: 0.9947 - val_loss: 3.2182 - val_accuracy: 0.6221\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 3.0454 - val_accuracy: 0.6187\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0344 - accuracy: 0.9956 - val_loss: 3.4466 - val_accuracy: 0.5853\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0212 - accuracy: 0.9974 - val_loss: 3.1731 - val_accuracy: 0.5987\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0322 - accuracy: 0.9939 - val_loss: 3.0356 - val_accuracy: 0.6221\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1058 - accuracy: 0.9711 - val_loss: 3.2502 - val_accuracy: 0.5853\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1818 - accuracy: 0.9544 - val_loss: 3.9593 - val_accuracy: 0.5485\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.3238 - accuracy: 0.9229 - val_loss: 3.6400 - val_accuracy: 0.5819\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.4049 - accuracy: 0.8887 - val_loss: 3.5070 - val_accuracy: 0.5619\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3622 - accuracy: 0.9001 - val_loss: 3.2295 - val_accuracy: 0.5853\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2958 - accuracy: 0.9246 - val_loss: 3.3983 - val_accuracy: 0.6221\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2248 - accuracy: 0.9360 - val_loss: 2.8420 - val_accuracy: 0.5853\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.1994 - accuracy: 0.9448 - val_loss: 3.1204 - val_accuracy: 0.6254\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1456 - accuracy: 0.9623 - val_loss: 3.1988 - val_accuracy: 0.5886\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.1025 - accuracy: 0.9746 - val_loss: 3.3953 - val_accuracy: 0.5886\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1030 - accuracy: 0.9720 - val_loss: 3.6617 - val_accuracy: 0.6020\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.2256 - accuracy: 0.9413 - val_loss: 4.1066 - val_accuracy: 0.5652\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1944 - accuracy: 0.9492 - val_loss: 3.3553 - val_accuracy: 0.5719\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0791 - accuracy: 0.9816 - val_loss: 3.2569 - val_accuracy: 0.6120\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0715 - accuracy: 0.9790 - val_loss: 3.6234 - val_accuracy: 0.5619\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0569 - accuracy: 0.9842 - val_loss: 2.9669 - val_accuracy: 0.5853\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0350 - accuracy: 0.9912 - val_loss: 3.0791 - val_accuracy: 0.6154\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0347 - accuracy: 0.9930 - val_loss: 2.8002 - val_accuracy: 0.6154\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0210 - accuracy: 0.9965 - val_loss: 2.8489 - val_accuracy: 0.6288\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0176 - accuracy: 0.9991 - val_loss: 2.8508 - val_accuracy: 0.6187\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0157 - accuracy: 0.9991 - val_loss: 2.8381 - val_accuracy: 0.6254\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 2.9069 - val_accuracy: 0.6154\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.9490 - val_accuracy: 0.6087\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.8878 - val_accuracy: 0.6288\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 2.8953 - val_accuracy: 0.6187\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0143 - accuracy: 0.9982 - val_loss: 3.1831 - val_accuracy: 0.5853\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0163 - accuracy: 0.9982 - val_loss: 3.0286 - val_accuracy: 0.6087\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0205 - accuracy: 0.9982 - val_loss: 3.0349 - val_accuracy: 0.6187\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0162 - accuracy: 0.9982 - val_loss: 2.9280 - val_accuracy: 0.6120\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 3.0002 - val_accuracy: 0.6054\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.9810 - val_accuracy: 0.6087\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.9750 - val_accuracy: 0.6187\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.9769 - val_accuracy: 0.6020\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.9689 - val_accuracy: 0.6087\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 2.9678 - val_accuracy: 0.6087\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.0069 - val_accuracy: 0.6187\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.9744 - val_accuracy: 0.6187\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.9581 - val_accuracy: 0.6221\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.9842 - val_accuracy: 0.6087\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.9742 - val_accuracy: 0.6054\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0135 - accuracy: 0.9991 - val_loss: 2.9979 - val_accuracy: 0.6087\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0163 - accuracy: 0.9982 - val_loss: 2.8933 - val_accuracy: 0.6321\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0167 - accuracy: 0.9982 - val_loss: 2.8945 - val_accuracy: 0.6488\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0148 - accuracy: 0.9982 - val_loss: 2.9082 - val_accuracy: 0.6221\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0386 - accuracy: 0.9912 - val_loss: 3.1053 - val_accuracy: 0.6120\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0288 - accuracy: 0.9939 - val_loss: 3.0140 - val_accuracy: 0.6187\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0363 - accuracy: 0.9939 - val_loss: 3.0061 - val_accuracy: 0.6187\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 3.0429 - val_accuracy: 0.6120\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0141 - accuracy: 0.9991 - val_loss: 2.9638 - val_accuracy: 0.6087\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 3.0486 - val_accuracy: 0.6087\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.9675 - val_accuracy: 0.6154\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0150 - accuracy: 0.9991 - val_loss: 2.9760 - val_accuracy: 0.6187\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0154 - accuracy: 0.9991 - val_loss: 2.9451 - val_accuracy: 0.6421\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.9256 - val_accuracy: 0.6355\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0134 - accuracy: 0.9991 - val_loss: 3.0049 - val_accuracy: 0.6154\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0145 - accuracy: 0.9991 - val_loss: 3.0237 - val_accuracy: 0.6388\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0142 - accuracy: 0.9991 - val_loss: 3.0199 - val_accuracy: 0.6254\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.1480 - val_accuracy: 0.6421\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 3.0362 - val_accuracy: 0.6522\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.9805 - val_accuracy: 0.6455\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.9802 - val_accuracy: 0.6455\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 3.0091 - val_accuracy: 0.6455\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 3.0067 - val_accuracy: 0.6488\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 3.0150 - val_accuracy: 0.6488\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.0125 - val_accuracy: 0.6455\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.0110 - val_accuracy: 0.6488\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.0079 - val_accuracy: 0.6522\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 3.0109 - val_accuracy: 0.6555\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 3.0037 - val_accuracy: 0.6522\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.9928 - val_accuracy: 0.6488\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.9878 - val_accuracy: 0.6555\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.9869 - val_accuracy: 0.6522\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.9983 - val_accuracy: 0.6589\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0021 - val_accuracy: 0.6622\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 3.0539 - val_accuracy: 0.6488\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 3.0668 - val_accuracy: 0.6488\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 3.0523 - val_accuracy: 0.6455\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0255 - val_accuracy: 0.6522\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.0137 - val_accuracy: 0.6522\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0110 - val_accuracy: 0.6488\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.0075 - val_accuracy: 0.6488\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.0088 - val_accuracy: 0.6488\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.0162 - val_accuracy: 0.6488\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.6522\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.0271 - val_accuracy: 0.6455\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.0322 - val_accuracy: 0.6455\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.0366 - val_accuracy: 0.6455\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.0357 - val_accuracy: 0.6421\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.0273 - val_accuracy: 0.6488\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.0179 - val_accuracy: 0.6455\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.0231 - val_accuracy: 0.6455\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.0406 - val_accuracy: 0.6421\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.0521 - val_accuracy: 0.6388\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.0562 - val_accuracy: 0.6421\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.0561 - val_accuracy: 0.6421\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.0565 - val_accuracy: 0.6455\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0532 - val_accuracy: 0.6388\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.0561 - val_accuracy: 0.6388\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.0638 - val_accuracy: 0.6421\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0652 - val_accuracy: 0.6321\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0641 - val_accuracy: 0.6355\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.0668 - val_accuracy: 0.6321\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0672 - val_accuracy: 0.6355\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0708 - val_accuracy: 0.6388\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.0744 - val_accuracy: 0.6388\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.0777 - val_accuracy: 0.6421\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.0774 - val_accuracy: 0.6321\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.0798 - val_accuracy: 0.6321\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.0701 - val_accuracy: 0.6321\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.0722 - val_accuracy: 0.6421\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.0748 - val_accuracy: 0.6388\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.0693 - val_accuracy: 0.6455\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.0690 - val_accuracy: 0.6455\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.0692 - val_accuracy: 0.6421\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.0702 - val_accuracy: 0.6421\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.0740 - val_accuracy: 0.6421\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.0775 - val_accuracy: 0.6421\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.0824 - val_accuracy: 0.6421\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.0889 - val_accuracy: 0.6488\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.0905 - val_accuracy: 0.6455\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.0959 - val_accuracy: 0.6421\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.0965 - val_accuracy: 0.6421\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.1002 - val_accuracy: 0.6488\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1035 - val_accuracy: 0.6488\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.0936 - val_accuracy: 0.6455\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.0875 - val_accuracy: 0.6421\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.0895 - val_accuracy: 0.6388\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1149 - val_accuracy: 0.6455\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.1336 - val_accuracy: 0.6455\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.1349 - val_accuracy: 0.6488\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1077 - val_accuracy: 0.6355\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1347 - val_accuracy: 0.6221\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.1481 - val_accuracy: 0.6455\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.1372 - val_accuracy: 0.6321\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1146 - val_accuracy: 0.6488\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.1317 - val_accuracy: 0.6488\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 3.1258 - val_accuracy: 0.6488\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.2292 - val_accuracy: 0.6087\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0521 - accuracy: 0.9869 - val_loss: 3.2109 - val_accuracy: 0.6087\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.3314 - accuracy: 0.9255 - val_loss: 4.6480 - val_accuracy: 0.4950\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.8331 - accuracy: 0.8265 - val_loss: 3.9126 - val_accuracy: 0.5184\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.9917 - accuracy: 0.7958 - val_loss: 2.9948 - val_accuracy: 0.6054\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.7224 - accuracy: 0.8449 - val_loss: 4.2468 - val_accuracy: 0.4849\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.5079 - accuracy: 0.8650 - val_loss: 4.2123 - val_accuracy: 0.5251\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.3729 - accuracy: 0.9080 - val_loss: 3.3882 - val_accuracy: 0.5719\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.2108 - accuracy: 0.9334 - val_loss: 2.6562 - val_accuracy: 0.6221\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1518 - accuracy: 0.9606 - val_loss: 2.5479 - val_accuracy: 0.6522\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0659 - accuracy: 0.9860 - val_loss: 2.6215 - val_accuracy: 0.6321\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0545 - accuracy: 0.9877 - val_loss: 2.4764 - val_accuracy: 0.6388\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0322 - accuracy: 0.9921 - val_loss: 2.6627 - val_accuracy: 0.6589\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 2.5184 - val_accuracy: 0.6622\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 2.4126 - val_accuracy: 0.6589\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0249 - accuracy: 0.9965 - val_loss: 2.4577 - val_accuracy: 0.6455\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0283 - accuracy: 0.9947 - val_loss: 2.3494 - val_accuracy: 0.6622\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0192 - accuracy: 0.9991 - val_loss: 2.3906 - val_accuracy: 0.6622\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0165 - accuracy: 0.9982 - val_loss: 2.4653 - val_accuracy: 0.6589\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.4572 - val_accuracy: 0.6589\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.4272 - val_accuracy: 0.6722\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.3863 - val_accuracy: 0.6722\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.3732 - val_accuracy: 0.6656\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.3790 - val_accuracy: 0.6689\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.3724 - val_accuracy: 0.6656\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.3803 - val_accuracy: 0.6555\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.3853 - val_accuracy: 0.6555\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0141 - accuracy: 0.9991 - val_loss: 2.5357 - val_accuracy: 0.6522\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.5826 - val_accuracy: 0.6455\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 2.4742 - val_accuracy: 0.6722\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.4698 - val_accuracy: 0.6722\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.4695 - val_accuracy: 0.6656\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.4722 - val_accuracy: 0.6622\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.4558 - val_accuracy: 0.6622\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.4531 - val_accuracy: 0.6488\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.4753 - val_accuracy: 0.6589\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.4790 - val_accuracy: 0.6555\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.4786 - val_accuracy: 0.6589\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.4730 - val_accuracy: 0.6589\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.4685 - val_accuracy: 0.6589\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.4812 - val_accuracy: 0.6589\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.4834 - val_accuracy: 0.6656\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0173 - accuracy: 0.9991 - val_loss: 2.4025 - val_accuracy: 0.6522\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0160 - accuracy: 0.9974 - val_loss: 2.5599 - val_accuracy: 0.6455\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.5930 - val_accuracy: 0.6722\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.6175 - val_accuracy: 0.6488\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.5122 - val_accuracy: 0.6656\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.4479 - val_accuracy: 0.6656\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.4880 - val_accuracy: 0.6589\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.5002 - val_accuracy: 0.6555\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.4963 - val_accuracy: 0.6455\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.4959 - val_accuracy: 0.6589\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.4954 - val_accuracy: 0.6555\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.6488\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.5340 - val_accuracy: 0.6522\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.5027 - val_accuracy: 0.6455\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.5127 - val_accuracy: 0.6522\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.5298 - val_accuracy: 0.6522\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.5475 - val_accuracy: 0.6455\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.5623 - val_accuracy: 0.6421\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.5834 - val_accuracy: 0.6555\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.5904 - val_accuracy: 0.6522\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.5277 - val_accuracy: 0.6622\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.9991 - val_loss: 2.5522 - val_accuracy: 0.6555\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9982 - val_loss: 2.5600 - val_accuracy: 0.6656\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0133 - accuracy: 0.9991 - val_loss: 2.7604 - val_accuracy: 0.6355\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.7066 - val_accuracy: 0.6589\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.7453 - val_accuracy: 0.6522\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.6765 - val_accuracy: 0.6656\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.6454 - val_accuracy: 0.6656\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.6398 - val_accuracy: 0.6589\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.6454 - val_accuracy: 0.6522\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.6245 - val_accuracy: 0.6488\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.6207 - val_accuracy: 0.6488\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.5874 - val_accuracy: 0.6522\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.5915 - val_accuracy: 0.6555\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.5931 - val_accuracy: 0.6455\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.5963 - val_accuracy: 0.6421\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.6010 - val_accuracy: 0.6388\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.6073 - val_accuracy: 0.6421\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.6142 - val_accuracy: 0.6555\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 2.5321 - val_accuracy: 0.6488\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0163 - accuracy: 0.9974 - val_loss: 2.9938 - val_accuracy: 0.6254\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0273 - accuracy: 0.9974 - val_loss: 2.7403 - val_accuracy: 0.6622\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0750 - accuracy: 0.9798 - val_loss: 3.0430 - val_accuracy: 0.6388\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.2419 - accuracy: 0.9465 - val_loss: 3.4559 - val_accuracy: 0.5886\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.2961 - accuracy: 0.9194 - val_loss: 3.3956 - val_accuracy: 0.5786\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3067 - accuracy: 0.9150 - val_loss: 2.6668 - val_accuracy: 0.6288\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.2009 - accuracy: 0.9395 - val_loss: 3.4065 - val_accuracy: 0.5819\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.2494 - accuracy: 0.9448 - val_loss: 2.8854 - val_accuracy: 0.5819\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.1438 - accuracy: 0.9632 - val_loss: 3.0207 - val_accuracy: 0.6120\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.1364 - accuracy: 0.9614 - val_loss: 3.2130 - val_accuracy: 0.5920\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0774 - accuracy: 0.9755 - val_loss: 3.0857 - val_accuracy: 0.5853\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0562 - accuracy: 0.9842 - val_loss: 3.5696 - val_accuracy: 0.5819\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0844 - accuracy: 0.9737 - val_loss: 3.9213 - val_accuracy: 0.5552\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0614 - accuracy: 0.9842 - val_loss: 3.3155 - val_accuracy: 0.5920\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 3.0585 - val_accuracy: 0.6054\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0389 - accuracy: 0.9912 - val_loss: 3.3545 - val_accuracy: 0.6054\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 3.4583 - val_accuracy: 0.6221\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 3.2523 - val_accuracy: 0.6221\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 3.1220 - val_accuracy: 0.6455\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 3.0205 - val_accuracy: 0.6488\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9991 - val_loss: 3.1878 - val_accuracy: 0.6154\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 3.1317 - val_accuracy: 0.6421\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 3.1178 - val_accuracy: 0.6254\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.9991 - val_loss: 3.2485 - val_accuracy: 0.6254\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0138 - accuracy: 0.9991 - val_loss: 3.0489 - val_accuracy: 0.6321\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0140 - accuracy: 0.9982 - val_loss: 3.1073 - val_accuracy: 0.6120\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 3.1501 - val_accuracy: 0.6221\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 3.1504 - val_accuracy: 0.6187\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 3.1592 - val_accuracy: 0.6187\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1717 - val_accuracy: 0.6321\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 3.1713 - val_accuracy: 0.6187\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1766 - val_accuracy: 0.6154\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.1660 - val_accuracy: 0.6154\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1466 - val_accuracy: 0.6154\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.1532 - val_accuracy: 0.6187\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.1497 - val_accuracy: 0.6221\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1466 - val_accuracy: 0.6221\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.1446 - val_accuracy: 0.6221\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 3.1459 - val_accuracy: 0.6187\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.1753 - val_accuracy: 0.6187\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.1901 - val_accuracy: 0.6254\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1847 - val_accuracy: 0.6254\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1838 - val_accuracy: 0.6321\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 3.1422 - val_accuracy: 0.6254\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.1485 - val_accuracy: 0.6221\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 3.1528 - val_accuracy: 0.6221\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.1521 - val_accuracy: 0.6221\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1519 - val_accuracy: 0.6221\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 3.1469 - val_accuracy: 0.6221\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1464 - val_accuracy: 0.6221\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1545 - val_accuracy: 0.6221\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1570 - val_accuracy: 0.6221\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1594 - val_accuracy: 0.6254\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1617 - val_accuracy: 0.6254\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1629 - val_accuracy: 0.6288\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1654 - val_accuracy: 0.6288\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1688 - val_accuracy: 0.6254\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1651 - val_accuracy: 0.6221\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1634 - val_accuracy: 0.6221\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1616 - val_accuracy: 0.6187\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0118 - accuracy: 0.9991 - val_loss: 3.3382 - val_accuracy: 0.6321\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 3.2548 - val_accuracy: 0.6254\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.2213 - val_accuracy: 0.6321\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.2061 - val_accuracy: 0.6321\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1704 - val_accuracy: 0.6288\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.1570 - val_accuracy: 0.6154\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.1558 - val_accuracy: 0.6221\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.1591 - val_accuracy: 0.6254\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.1553 - val_accuracy: 0.6254\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.1526 - val_accuracy: 0.6254\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.1554 - val_accuracy: 0.6254\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.1541 - val_accuracy: 0.6288\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 3.1595 - val_accuracy: 0.6321\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1585 - val_accuracy: 0.6321\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1583 - val_accuracy: 0.6288\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1615 - val_accuracy: 0.6254\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1627 - val_accuracy: 0.6288\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.1654 - val_accuracy: 0.6321\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.2186 - val_accuracy: 0.6288\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1982 - val_accuracy: 0.6355\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0133 - accuracy: 0.9991 - val_loss: 3.4293 - val_accuracy: 0.6087\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0911 - accuracy: 0.9869 - val_loss: 3.1926 - val_accuracy: 0.6087\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.1681 - accuracy: 0.9527 - val_loss: 3.5614 - val_accuracy: 0.5719\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.4151 - accuracy: 0.8975 - val_loss: 7.3043 - val_accuracy: 0.3946\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.6768 - accuracy: 0.8668 - val_loss: 3.4929 - val_accuracy: 0.5753\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.5235 - accuracy: 0.8712 - val_loss: 4.1375 - val_accuracy: 0.4983\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.2999 - accuracy: 0.9220 - val_loss: 3.2027 - val_accuracy: 0.6020\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.1482 - accuracy: 0.9571 - val_loss: 3.1417 - val_accuracy: 0.6321\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0656 - accuracy: 0.9781 - val_loss: 3.1446 - val_accuracy: 0.5819\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0595 - accuracy: 0.9851 - val_loss: 2.8771 - val_accuracy: 0.6120\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0312 - accuracy: 0.9965 - val_loss: 2.9849 - val_accuracy: 0.6087\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0771 - accuracy: 0.9904 - val_loss: 2.8583 - val_accuracy: 0.6355\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0373 - accuracy: 0.9956 - val_loss: 3.0032 - val_accuracy: 0.6355\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0464 - accuracy: 0.9921 - val_loss: 2.8873 - val_accuracy: 0.6321\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0673 - accuracy: 0.9895 - val_loss: 3.0563 - val_accuracy: 0.6488\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0734 - accuracy: 0.9869 - val_loss: 3.0034 - val_accuracy: 0.6388\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0352 - accuracy: 0.9930 - val_loss: 3.2025 - val_accuracy: 0.6288\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0497 - accuracy: 0.9930 - val_loss: 3.1339 - val_accuracy: 0.6288\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0492 - accuracy: 0.9895 - val_loss: 3.1335 - val_accuracy: 0.6120\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0337 - accuracy: 0.9939 - val_loss: 3.0484 - val_accuracy: 0.6187\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 3.0579 - val_accuracy: 0.5953\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0298 - accuracy: 0.9947 - val_loss: 2.9427 - val_accuracy: 0.6421\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0291 - accuracy: 0.9947 - val_loss: 2.7359 - val_accuracy: 0.6154\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0225 - accuracy: 0.9947 - val_loss: 3.0647 - val_accuracy: 0.6355\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0136 - accuracy: 0.9991 - val_loss: 2.8874 - val_accuracy: 0.6455\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0186 - accuracy: 0.9991 - val_loss: 2.8949 - val_accuracy: 0.6522\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0142 - accuracy: 0.9991 - val_loss: 2.8870 - val_accuracy: 0.6355\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.8510 - val_accuracy: 0.6321\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.8035 - val_accuracy: 0.6421\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.6388\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7929 - val_accuracy: 0.6388\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.6555\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.7894 - val_accuracy: 0.6589\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.7777 - val_accuracy: 0.6555\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.7620 - val_accuracy: 0.6555\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.7454 - val_accuracy: 0.6589\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.7457 - val_accuracy: 0.6689\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.7508 - val_accuracy: 0.6689\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.7498 - val_accuracy: 0.6722\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0248 - accuracy: 0.9974 - val_loss: 2.9729 - val_accuracy: 0.6488\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.8677 - val_accuracy: 0.6689\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.8384 - val_accuracy: 0.6689\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8267 - val_accuracy: 0.6622\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.8724 - val_accuracy: 0.6589\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8666 - val_accuracy: 0.6589\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8603 - val_accuracy: 0.6622\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.8712 - val_accuracy: 0.6555\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.8160 - val_accuracy: 0.6656\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8111 - val_accuracy: 0.6689\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.7880 - val_accuracy: 0.6722\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.7970 - val_accuracy: 0.6589\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.7926 - val_accuracy: 0.6622\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.7876 - val_accuracy: 0.6722\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7898 - val_accuracy: 0.6656\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.7918 - val_accuracy: 0.6689\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7923 - val_accuracy: 0.6656\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.6656\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7864 - val_accuracy: 0.6789\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7858 - val_accuracy: 0.6789\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.7834 - val_accuracy: 0.6789\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8218 - val_accuracy: 0.6689\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8390 - val_accuracy: 0.6656\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8425 - val_accuracy: 0.6555\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8416 - val_accuracy: 0.6555\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8397 - val_accuracy: 0.6555\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8336 - val_accuracy: 0.6555\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8315 - val_accuracy: 0.6589\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8313 - val_accuracy: 0.6589\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8289 - val_accuracy: 0.6589\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8133 - val_accuracy: 0.6555\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.7766 - val_accuracy: 0.6622\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.7969 - val_accuracy: 0.6555\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8466 - val_accuracy: 0.6455\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8225 - val_accuracy: 0.6522\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8230 - val_accuracy: 0.6421\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8999 - val_accuracy: 0.6522\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.9465 - val_accuracy: 0.6388\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.9141 - val_accuracy: 0.6488\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8851 - val_accuracy: 0.6555\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8780 - val_accuracy: 0.6589\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8570 - val_accuracy: 0.6589\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8571 - val_accuracy: 0.6589\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 3.0871 - val_accuracy: 0.6388\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.9356 - val_accuracy: 0.6488\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0151 - accuracy: 0.9991 - val_loss: 3.0051 - val_accuracy: 0.6388\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0325 - accuracy: 0.9947 - val_loss: 3.0602 - val_accuracy: 0.6488\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0448 - accuracy: 0.9947 - val_loss: 3.3156 - val_accuracy: 0.6221\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1327 - accuracy: 0.9597 - val_loss: 3.6749 - val_accuracy: 0.5518\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3168 - accuracy: 0.9097 - val_loss: 3.9832 - val_accuracy: 0.5385\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.2685 - accuracy: 0.9273 - val_loss: 3.6545 - val_accuracy: 0.5652\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.3015 - accuracy: 0.9273 - val_loss: 3.2799 - val_accuracy: 0.5920\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.2232 - accuracy: 0.9299 - val_loss: 3.8680 - val_accuracy: 0.5886\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.2389 - accuracy: 0.9316 - val_loss: 2.9101 - val_accuracy: 0.6321\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.2861 - accuracy: 0.9159 - val_loss: 3.3214 - val_accuracy: 0.5886\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.2173 - accuracy: 0.9308 - val_loss: 2.9002 - val_accuracy: 0.5953\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1109 - accuracy: 0.9702 - val_loss: 3.2700 - val_accuracy: 0.5886\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1014 - accuracy: 0.9676 - val_loss: 2.7423 - val_accuracy: 0.6321\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0558 - accuracy: 0.9825 - val_loss: 3.1667 - val_accuracy: 0.6120\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 1s 40ms/step - loss: 0.0531 - accuracy: 0.9912 - val_loss: 2.8254 - val_accuracy: 0.6488\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0248 - accuracy: 0.9982 - val_loss: 2.7946 - val_accuracy: 0.6288\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0225 - accuracy: 0.9965 - val_loss: 2.6229 - val_accuracy: 0.6622\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0148 - accuracy: 0.9991 - val_loss: 2.6741 - val_accuracy: 0.6455\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.7003 - val_accuracy: 0.6555\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7624 - val_accuracy: 0.6488\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.9991 - val_loss: 2.8995 - val_accuracy: 0.6421\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 2.8048 - val_accuracy: 0.6421\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0130 - accuracy: 0.9991 - val_loss: 2.8202 - val_accuracy: 0.6388\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.8486 - val_accuracy: 0.6455\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.8603 - val_accuracy: 0.6321\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.8430 - val_accuracy: 0.6421\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8311 - val_accuracy: 0.6522\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8192 - val_accuracy: 0.6522\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.8182 - val_accuracy: 0.6589\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.6589\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8202 - val_accuracy: 0.6622\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8100 - val_accuracy: 0.6622\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.8079 - val_accuracy: 0.6555\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.7987 - val_accuracy: 0.6589\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.6589\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.7988 - val_accuracy: 0.6589\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8020 - val_accuracy: 0.6589\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8122 - val_accuracy: 0.6589\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8193 - val_accuracy: 0.6522\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8254 - val_accuracy: 0.6589\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.6622\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8292 - val_accuracy: 0.6589\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8255 - val_accuracy: 0.6555\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8251 - val_accuracy: 0.6555\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8254 - val_accuracy: 0.6589\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.9212 - val_accuracy: 0.6622\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.9220 - val_accuracy: 0.6589\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.8871 - val_accuracy: 0.6622\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8844 - val_accuracy: 0.6622\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.6555\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8872 - val_accuracy: 0.6522\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.8832 - val_accuracy: 0.6522\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8788 - val_accuracy: 0.6488\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8763 - val_accuracy: 0.6488\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8784 - val_accuracy: 0.6455\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8788 - val_accuracy: 0.6488\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.8487 - val_accuracy: 0.6555\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8420 - val_accuracy: 0.6589\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8407 - val_accuracy: 0.6589\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8428 - val_accuracy: 0.6589\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8470 - val_accuracy: 0.6589\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8520 - val_accuracy: 0.6555\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8547 - val_accuracy: 0.6589\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8638 - val_accuracy: 0.6555\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.8615 - val_accuracy: 0.6589\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8605 - val_accuracy: 0.6589\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8638 - val_accuracy: 0.6622\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8684 - val_accuracy: 0.6555\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8763 - val_accuracy: 0.6589\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8807 - val_accuracy: 0.6589\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8859 - val_accuracy: 0.6589\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8892 - val_accuracy: 0.6622\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.8992 - val_accuracy: 0.6589\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.9005 - val_accuracy: 0.6589\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8966 - val_accuracy: 0.6689\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8826 - val_accuracy: 0.6622\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8828 - val_accuracy: 0.6622\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8879 - val_accuracy: 0.6656\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8930 - val_accuracy: 0.6656\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8929 - val_accuracy: 0.6656\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.8977 - val_accuracy: 0.6656\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9031 - val_accuracy: 0.6589\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9071 - val_accuracy: 0.6622\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9069 - val_accuracy: 0.6589\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9090 - val_accuracy: 0.6589\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9139 - val_accuracy: 0.6555\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9149 - val_accuracy: 0.6555\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9192 - val_accuracy: 0.6522\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9197 - val_accuracy: 0.6522\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9186 - val_accuracy: 0.6522\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 1s 42ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9176 - val_accuracy: 0.6488\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9138 - val_accuracy: 0.6555\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9127 - val_accuracy: 0.6589\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9129 - val_accuracy: 0.6622\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9125 - val_accuracy: 0.6622\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9196 - val_accuracy: 0.6589\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9240 - val_accuracy: 0.6555\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.6488\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9165 - val_accuracy: 0.6522\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9173 - val_accuracy: 0.6522\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.9187 - val_accuracy: 0.6522\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9171 - val_accuracy: 0.6555\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9203 - val_accuracy: 0.6555\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9217 - val_accuracy: 0.6555\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.1098 - val_accuracy: 0.6689\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.9991 - val_loss: 2.9888 - val_accuracy: 0.6522\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.9350 - val_accuracy: 0.6455\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9162 - val_accuracy: 0.6421\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.9082 - val_accuracy: 0.6421\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9025 - val_accuracy: 0.6455\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9055 - val_accuracy: 0.6488\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9088 - val_accuracy: 0.6488\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9172 - val_accuracy: 0.6522\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9206 - val_accuracy: 0.6522\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9234 - val_accuracy: 0.6555\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9230 - val_accuracy: 0.6555\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9231 - val_accuracy: 0.6555\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9271 - val_accuracy: 0.6555\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.9339 - val_accuracy: 0.6555\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9326 - val_accuracy: 0.6522\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9318 - val_accuracy: 0.6589\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9389 - val_accuracy: 0.6589\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9367 - val_accuracy: 0.6555\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 3.0290 - val_accuracy: 0.6589\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0243 - accuracy: 0.9982 - val_loss: 3.4981 - val_accuracy: 0.6020\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1198 - accuracy: 0.9720 - val_loss: 4.2283 - val_accuracy: 0.5452\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.8613 - accuracy: 0.8221 - val_loss: 5.8487 - val_accuracy: 0.4548\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.5677 - accuracy: 0.8659 - val_loss: 3.6291 - val_accuracy: 0.5786\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.2957 - accuracy: 0.9132 - val_loss: 2.7199 - val_accuracy: 0.6054\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1531 - accuracy: 0.9518 - val_loss: 3.0771 - val_accuracy: 0.5853\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.1141 - accuracy: 0.9693 - val_loss: 3.1650 - val_accuracy: 0.5753\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0895 - accuracy: 0.9720 - val_loss: 3.3762 - val_accuracy: 0.5920\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0702 - accuracy: 0.9790 - val_loss: 2.7650 - val_accuracy: 0.6355\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 2.8572 - val_accuracy: 0.6555\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0464 - accuracy: 0.9895 - val_loss: 2.9454 - val_accuracy: 0.6221\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0351 - accuracy: 0.9947 - val_loss: 2.7987 - val_accuracy: 0.6254\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0460 - accuracy: 0.9904 - val_loss: 2.7777 - val_accuracy: 0.6455\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0602 - accuracy: 0.9833 - val_loss: 3.2968 - val_accuracy: 0.5686\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0585 - accuracy: 0.9860 - val_loss: 2.7637 - val_accuracy: 0.6522\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 1s 41ms/step - loss: 0.0432 - accuracy: 0.9869 - val_loss: 3.7474 - val_accuracy: 0.5853\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0504 - accuracy: 0.9860 - val_loss: 2.9576 - val_accuracy: 0.6355\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0513 - accuracy: 0.9939 - val_loss: 2.6688 - val_accuracy: 0.6522\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 2.4713 - val_accuracy: 0.6355\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0151 - accuracy: 0.9982 - val_loss: 2.5080 - val_accuracy: 0.6355\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.5166 - val_accuracy: 0.6388\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.5856 - val_accuracy: 0.6388\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.6021 - val_accuracy: 0.6455\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.6034 - val_accuracy: 0.6388\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.5946 - val_accuracy: 0.6421\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.6388\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.5945 - val_accuracy: 0.6388\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.5928 - val_accuracy: 0.6355\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.6355\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.5866 - val_accuracy: 0.6355\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.6355\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 2.6000 - val_accuracy: 0.6455\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.6696 - val_accuracy: 0.6522\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7018 - val_accuracy: 0.6355\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.7034 - val_accuracy: 0.6455\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.6960 - val_accuracy: 0.6355\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.6917 - val_accuracy: 0.6321\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.7157 - val_accuracy: 0.6355\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.7166 - val_accuracy: 0.6421\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.6810 - val_accuracy: 0.6455\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.6591 - val_accuracy: 0.6321\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.6554 - val_accuracy: 0.6321\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.6831 - val_accuracy: 0.6421\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.6934 - val_accuracy: 0.6421\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.6889 - val_accuracy: 0.6388\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.6863 - val_accuracy: 0.6421\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 2.6913 - val_accuracy: 0.6388\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0123 - accuracy: 0.9991 - val_loss: 2.7958 - val_accuracy: 0.6421\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.7930 - val_accuracy: 0.6221\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.7850 - val_accuracy: 0.6254\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.7703 - val_accuracy: 0.6288\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.7645 - val_accuracy: 0.6288\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.7449 - val_accuracy: 0.6288\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.8951 - val_accuracy: 0.6321\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.8133 - val_accuracy: 0.6221\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.7765 - val_accuracy: 0.6321\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.7563 - val_accuracy: 0.6288\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.7548 - val_accuracy: 0.6421\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.7504 - val_accuracy: 0.6355\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.7425 - val_accuracy: 0.6321\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.7364 - val_accuracy: 0.6321\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.7353 - val_accuracy: 0.6355\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.7149 - val_accuracy: 0.6388\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.6898 - val_accuracy: 0.6321\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.6924 - val_accuracy: 0.6321\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.6983 - val_accuracy: 0.6321\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7033 - val_accuracy: 0.6355\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.7050 - val_accuracy: 0.6355\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7062 - val_accuracy: 0.6355\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7102 - val_accuracy: 0.6355\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.7108 - val_accuracy: 0.6388\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7129 - val_accuracy: 0.6388\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.7045 - val_accuracy: 0.6388\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7036 - val_accuracy: 0.6488\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.7045 - val_accuracy: 0.6421\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.7145 - val_accuracy: 0.6421\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7199 - val_accuracy: 0.6455\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.7190 - val_accuracy: 0.6455\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.7153 - val_accuracy: 0.6455\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.7074 - val_accuracy: 0.6421\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.7108 - val_accuracy: 0.6388\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.7213 - val_accuracy: 0.6388\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.7236 - val_accuracy: 0.6421\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.7241 - val_accuracy: 0.6388\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.6321\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.6960 - val_accuracy: 0.6321\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.7008 - val_accuracy: 0.6421\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.7024 - val_accuracy: 0.6388\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.7101 - val_accuracy: 0.6388\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 1s 38ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.7194 - val_accuracy: 0.6388\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.7303 - val_accuracy: 0.6388\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7299 - val_accuracy: 0.6421\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7325 - val_accuracy: 0.6421\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7329 - val_accuracy: 0.6421\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7338 - val_accuracy: 0.6421\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7300 - val_accuracy: 0.6388\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7283 - val_accuracy: 0.6388\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7293 - val_accuracy: 0.6522\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7299 - val_accuracy: 0.6522\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7318 - val_accuracy: 0.6488\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.7427 - val_accuracy: 0.6522\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.7462 - val_accuracy: 0.6522\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.7496 - val_accuracy: 0.6522\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.7568 - val_accuracy: 0.6488\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.7813 - val_accuracy: 0.6455\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.6488\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.8720 - val_accuracy: 0.6455\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 1s 34ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.8539 - val_accuracy: 0.6488\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.8467 - val_accuracy: 0.6488\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.8346 - val_accuracy: 0.6421\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 1s 32ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.8277 - val_accuracy: 0.6421\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 1s 39ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.8229 - val_accuracy: 0.6421\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.8175 - val_accuracy: 0.6421\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 1s 35ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.8159 - val_accuracy: 0.6421\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 1s 31ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.8287 - val_accuracy: 0.6421\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 1s 37ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.6455\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "history=model.fit(x_train, y_train, batch_size=64, epochs=1000, validation_data=(x_test, y_test), shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pjJv7YRF_Ds",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "9d7a1195-7223-46e6-f77b-b6300a942d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 19ms/step - loss: 2.8366 - accuracy: 0.6455\n",
            "Accuracy of our model on test data :  64.54849243164062 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\n",
        "\n",
        "epochs = [i for i in range(1000)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "test_acc = history.history['val_accuracy']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "fig.set_size_inches(20,6)\n",
        "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
        "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
        "ax[0].set_title('Training & Testing Loss')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
        "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
        "ax[1].set_title('Training & Testing Accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('LSTM.h5')"
      ],
      "metadata": {
        "id": "m5L9W68fsJSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CB50VlYww0Vt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}